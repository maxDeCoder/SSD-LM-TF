{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 17:18:47.732425: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-07 17:18:47.796438: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-07 17:18:47.796474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-07 17:18:47.798215: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-07 17:18:47.809049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-07 17:18:49.116208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-07 17:18:52.351502: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:18:52.400284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:18:52.402147: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:18:52.591033: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:18:52.592933: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:18:52.594647: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:18:52.596304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14184 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95 # Change this value as per requirement\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import datasets\n",
    "import pickle as pkl\n",
    "import keras_nlp\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Lambda, Input, Softmax, Add, Concatenate\n",
    "from tensorflow.keras import Model\n",
    "from random import randint\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from tensorflow import keras\n",
    "from transformers import RobertaTokenizerFast, TFRobertaForCausalLM, TFRobertaModel, TFRobertaForMaskedLM, get_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 50\n",
    "C = 20\n",
    "B = L-C\n",
    "K = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"Skylion007/openwebtext\", streaming=True, split='train')\n",
    "\n",
    "# num_rows_to_read = 500000\n",
    "# texts = []\n",
    "\n",
    "# for i, item in enumerate(tqdm(dataset, total=num_rows_to_read)):\n",
    "#     text = item['text']\n",
    "#     if i < num_rows_to_read:\n",
    "#         texts.append(text)\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pkl.load(open('./data/500k-row.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer and endless datagenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_path = 'roberta-large'\n",
    "tf_hub_roberta_path = 'roberta_base_en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(roberta_path)\n",
    "\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text():\n",
    "    while True:\n",
    "        text = texts[randint(0, len(texts))]\n",
    "\n",
    "        tokens = tokenizer.encode_plus(text, return_tensors='np')\n",
    "        \n",
    "        start_index = np.random.randint(0, tokens['input_ids'].shape[-1]-L)\n",
    "        \n",
    "        input_ids = tokens['input_ids'][0][start_index:start_index+L]\n",
    "        attention_mask = tokens['attention_mask'][0][start_index:start_index+L]\n",
    "\n",
    "        yield input_ids, attention_mask\n",
    "\n",
    "def dict_map(input_ids, attention_mask):\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 2500\n",
    "beta = np.linspace(0.0001, 0.02, timesteps)\n",
    "\n",
    "alpha = 1 - beta\n",
    "alpha_bar = np.cumprod(alpha, 0)\n",
    "alpha_bar = np.concatenate((np.array([1.]), alpha_bar[:-1]), axis=0)\n",
    "sqrt_alpha_bar = np.sqrt(alpha_bar)\n",
    "one_minus_sqrt_alpha_bar = np.sqrt(1-alpha_bar)\n",
    "\n",
    "def set_key(key):\n",
    "    np.random.seed(key)\n",
    "\n",
    "def forward_noise(x_0, t, key=0):\n",
    "    set_key(key)\n",
    "    noise = np.random.normal(size=x_0.shape)\n",
    "    reshaped_sqrt_alpha_bar_t = np.reshape(np.take(sqrt_alpha_bar, t), (-1, 1, 1))\n",
    "    reshaped_one_minus_sqrt_alpha_bar_t = np.reshape(np.take(one_minus_sqrt_alpha_bar, t), (-1, 1, 1))\n",
    "    noisy_image = reshaped_sqrt_alpha_bar_t  * x_0 + reshaped_one_minus_sqrt_alpha_bar_t  * noise\n",
    "    return noisy_image, noise\n",
    "\n",
    "def generate_timestamp(num, key=0):\n",
    "    set_key(key)\n",
    "    return tf.random.uniform(shape=[num], minval=0, maxval=timesteps, dtype=tf.int32)\n",
    "\n",
    "def tokens_to_logits(toks):\n",
    "    toks = tf.cast(toks, dtype=tf.int32)\n",
    "    return tf.one_hot(toks, vocab_size, K, -K, dtype=tf.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 17:19:01.538881: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.541153: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.542900: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.545006: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.546793: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.548682: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.550499: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.552254: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-07 17:19:01.553985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14184 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.batch_encode_plus([\"This is one\", \"This is two\"], return_tensors='tf')['input_ids']\n",
    "logits = tokens_to_logits(tokens)\n",
    "noised, noise = forward_noise(logits, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimizer\n",
    "```optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)```\n",
    "\n",
    "- timestep encoder\n",
    "```timestep_layer = torch.nn.Linear(1, hidden_size, bias=True)```\n",
    "\n",
    "- embedding sum layer\n",
    "```embedding_sum_layer = torch.nn.Linear(vocab_size, hidden_size, bias=False)```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import RoBERTa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta = keras_nlp.models.RobertaBackbone.from_preset(tf_hub_roberta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = roberta.get_layer(\"embeddings\")\n",
    "# embedding_layer_norm = roberta.get_layer(\"embeddings_layer_norm\")\n",
    "# embeddings_dropout = roberta.get_layer(\"embeddings_dropout\")\n",
    "\n",
    "# roberta_embedder_context = Model(inputs=embedding.input, outputs=embeddings_dropout.output, name='roberta_embedder_context')\n",
    "# roberta_embedder_diffusion = Model(inputs=embedding.input, outputs=embeddings_dropout.output, name='roberta_embedder_diffusion')\n",
    "# hidden_size = embedding.weights[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_input = Input(shape=(1), name='timestamp_input', dtype=tf.int32)\n",
    "# timestamp_embeddings = Dense(hidden_size, name='timestamp_embeddings')(timestamp_input)\n",
    "# timestamp_encoder = Model(inputs=timestamp_input, outputs=timestamp_embeddings, name='timestamp_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_ids = Input(shape=(L, hidden_size), name='new_token_ids')\n",
    "# padding_mask = Input(shape=(L), name='new_padding_mask')\n",
    "\n",
    "# x = roberta.layers[5](token_ids, padding_mask=padding_mask)\n",
    "\n",
    "# for i in range(6, len(roberta.layers)):\n",
    "#     x = roberta.layers[i](x, padding_mask=padding_mask)\n",
    "\n",
    "# new_roberta = Model(inputs=[token_ids, padding_mask], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_roberta.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    sample_text, \n",
    "    output_signature=(\n",
    "       tf.TensorSpec(shape=(L), dtype=tf.int32),\n",
    "       tf.TensorSpec(shape=(L), dtype=tf.int32),\n",
    "    )).batch(BATCH_SIZE).map(dict_map).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForMaskedLM: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'tf_roberta_for_masked_lm/roberta/embeddings/word_embeddings/weight:0' shape=(50265, 1024) dtype=float32, numpy=\n",
       "array([[-0.140625  , -0.0096283 ,  0.03909302, ...,  0.05078125,\n",
       "        -0.00592422, -0.03604126],\n",
       "       [ 0.0078125 , -0.015625  ,  0.015625  , ..., -0.015625  ,\n",
       "         0.02305603,  0.015625  ],\n",
       "       [-0.08282471, -0.0007    , -0.11737061, ...,  0.10864258,\n",
       "         0.06964111, -0.0355835 ],\n",
       "       ...,\n",
       "       [ 0.03930664,  0.00305557,  0.04650879, ..., -0.02404785,\n",
       "        -0.05050659,  0.03424072],\n",
       "       [ 0.04986572,  0.02723694,  0.04125977, ..., -0.0369873 ,\n",
       "        -0.00996399,  0.00713348],\n",
       "       [-0.01489258, -0.01136017, -0.02224731, ...,  0.04406738,\n",
       "         0.0116272 , -0.03302002]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta = TFRobertaForMaskedLM.from_pretrained(roberta_path)\n",
    "roberta.resize_token_embeddings(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_embedder = roberta.get_input_embeddings()\n",
    "hidden_size = roberta.get_input_embeddings().weight.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_input = Input(shape=(1), name='timestamp_input', dtype=tf.int32)\n",
    "timestamp_embeddings = Dense(hidden_size, name='timestamp_embeddings')(timestamp_input)\n",
    "timestamp_encoder = Model(inputs=timestamp_input, outputs=timestamp_embeddings, name='timestamp_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_text_input = Input(shape=(B, vocab_size), name='diffusion text input')\n",
    "embedding_sum_layer = Dense(hidden_size, use_bias=False, name='middle_embeddings')(preprocess_text_input)\n",
    "pertubed_inputs = Softmax(name='softmax')(embedding_sum_layer)\n",
    "diffusion_preprocessor = Model(inputs=[preprocess_text_input], outputs=[pertubed_inputs])\n",
    "\n",
    "diffusion_preprocessor.layers[1].set_weights([roberta_embedder.weights[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 17:19:06.576956: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "max_steps = 50000\n",
    "decay_steps = 1000\n",
    "base_lr = 1e-4\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    base_lr,\n",
    "    decay_steps,\n",
    "    alpha=0.1\n",
    ")\n",
    "optimizer_preprocessor=keras.optimizers.AdamW(learning_rate=lr_scheduler)\n",
    "optimizer_embedder=keras.optimizers.AdamW(learning_rate=lr_scheduler)\n",
    "optimizer_roberta=keras.optimizers.AdamW(learning_rate=lr_scheduler)\n",
    "\n",
    "optimizer_preprocessor.build(diffusion_preprocessor.trainable_weights)\n",
    "optimizer_embedder.build(roberta_embedder.trainable_weights)\n",
    "optimizer_roberta.build(roberta.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985: 7.5660467147827155\r"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < max_steps:\n",
    "    test_batch = dataset.as_numpy_iterator().next()\n",
    "    test_ids = test_batch['input_ids']\n",
    "    attention_mask = test_batch['attention_mask']\n",
    "\n",
    "    context = test_ids[:, :C]\n",
    "    diffusion_text = test_ids[:, C:L]\n",
    "\n",
    "    diffusion_logits = tokens_to_logits(diffusion_text)\n",
    "\n",
    "    t = randint(0, timesteps)\n",
    "\n",
    "    t_embed = timestamp_encoder(np.array([t]))\n",
    "\n",
    "    diffusion_logits, noise = forward_noise(diffusion_logits, t)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        perturbed_input_text = diffusion_preprocessor(diffusion_logits)\n",
    "        diffusion_stuff = perturbed_input_text + t_embed\n",
    "\n",
    "        context_embeds = roberta_embedder(context)\n",
    "\n",
    "        final_embeds = tf.concat((context_embeds, perturbed_input_text), axis=1)\n",
    "\n",
    "        outputs = roberta.call(inputs_embeds=final_embeds, output_hidden_states=False).logits\n",
    "        diffusion_outputs = outputs[:, C:]\n",
    "        loss_value = keras.losses.sparse_categorical_crossentropy(diffusion_text, diffusion_outputs, from_logits=True)\n",
    "        loss_value = tf.math.reduce_mean(keras.losses.sparse_categorical_crossentropy(diffusion_text, diffusion_outputs, from_logits=True))\n",
    "\n",
    "    preprocessor_grads, embedder_grads, model_grads = tape.gradient(loss_value, [diffusion_preprocessor.trainable_weights, roberta_embedder.trainable_weights, roberta.trainable_weights])\n",
    "\n",
    "    optimizer_preprocessor.apply_gradients(zip(preprocessor_grads, diffusion_preprocessor.trainable_weights))\n",
    "    optimizer_embedder.apply_gradients(zip(embedder_grads, roberta_embedder.trainable_weights))\n",
    "    optimizer_roberta.apply_gradients(zip(model_grads, roberta.trainable_weights))\n",
    "\n",
    "    print(f\"{i}: {loss_value}\", end='\\r')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
